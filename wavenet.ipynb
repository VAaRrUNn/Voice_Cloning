{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CasualDilatedConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1D = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, bias=False, padding='same')\n",
    "        self.ignoreOutIndex = (kernel_size - 1) * dilation\n",
    "        self.conv1D.weight.data.fill_(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv1D(x)[..., :-self.ignoreOutIndex]\n",
    "\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.conv1d = nn.Conv1d(in_channels, in_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, skipConnection):\n",
    "        # as b c outputsize -> skipConnection size\n",
    "        out = torch.mean(skipConnection, dim=0)\n",
    "\n",
    "        for i in range(2):\n",
    "            out = self.relu(out)\n",
    "            out = self.conv1d(out)\n",
    "        return self.softmax(out)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, res_channels, skip_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.casualDilatedConv1D = CasualDilatedConv1D(res_channels, res_channels, kernel_size, dilation=dilation)\n",
    "        self.resConv1D = nn.Conv1d(res_channels, res_channels, kernel_size=1)\n",
    "        self.skipConv1D = nn.Conv1d(res_channels, skip_channels, kernel_size=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputX, skipSize):\n",
    "        x = self.casualDilatedConv1D(inputX)\n",
    "        x1 = self.tanh(x)\n",
    "        x2 = self.sigmoid(x)\n",
    "        x = x1 * x2\n",
    "        resOutput = self.resConv1D(x)\n",
    "        resOutput = resOutput + inputX[..., -resOutput.size(2):]\n",
    "        skipOutput = self.skipConv1D(x)\n",
    "        skipOutput = skipOutput[..., -skipSize:]\n",
    "        return resOutput, skipOutput\n",
    "\n",
    "\n",
    "class StackOfResBlocks(nn.Module):\n",
    "\n",
    "    def __init__(self, stack_size, layer_size, res_channels, skip_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        buildDilationFunc = np.vectorize(self.buildDilation)\n",
    "        dilations = buildDilationFunc(stack_size, layer_size)\n",
    "        self.resBlocks = []\n",
    "        for s,dilationPerStack in enumerate(dilations):\n",
    "            for l,dilation in enumerate(dilationPerStack):\n",
    "                resBlock=ResBlock(res_channels, skip_channels, kernel_size, dilation)\n",
    "                self.add_module(f'resBlock_{s}_{l}', resBlock) # Add modules manually\n",
    "                self.resBlocks.append(resBlock)\n",
    "\n",
    "    def buildDilation(self, stack_size, layer_size):\n",
    "        # stack1=[1,2,4,8,16,...512]\n",
    "        dilationsForAllStacks = []\n",
    "        for stack in range(stack_size):\n",
    "            dilations = []\n",
    "            for layer in range(layer_size):\n",
    "                dilations.append(2 ** layer)\n",
    "            dilationsForAllStacks.append(dilations)\n",
    "        return dilationsForAllStacks\n",
    "\n",
    "    def forward(self, x, skipSize):\n",
    "        resOutput = x\n",
    "        skipOutputs = []\n",
    "        for resBlock in self.resBlocks:\n",
    "            resOutput, skipOutput = resBlock(resOutput, skipSize)\n",
    "            skipOutputs.append(skipOutput)\n",
    "        return resOutput, torch.stack(skipOutputs)\n",
    "\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stack_size, layer_size):\n",
    "        super().__init__()\n",
    "        self.stack_size = stack_size\n",
    "        self.layer_size = layer_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.casualConv1D = CasualDilatedConv1D(in_channels, in_channels, kernel_size, dilation=1)\n",
    "        self.stackResBlock = StackOfResBlocks(self.stack_size, self.layer_size, in_channels, out_channels, kernel_size)\n",
    "        self.denseLayer = DenseLayer(out_channels)\n",
    "\n",
    "\n",
    "    def calculateReceptiveField(self):\n",
    "        return np.sum([(self.kernel_size - 1) * (2 ** l) for l in range(self.layer_size)] * self.stack_size)\n",
    "\n",
    "    def calculateOutputSize(self, x):\n",
    "        return int(x.size(2)) - self.calculateReceptiveField()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: b c t -> input data size\n",
    "        x = self.casualConv1D(x)\n",
    "        skipSize = self.calculateOutputSize(x)\n",
    "        _, skipConnections = self.stackResBlock(x, skipSize)\n",
    "        dense=self.denseLayer(skipConnections)\n",
    "        return dense\n",
    "    \n",
    "class WaveNetClassifier(nn.Module):\n",
    "    def __init__(self,seqLen,output_size):\n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.wavenet=WaveNet(1,1,2,3,4)\n",
    "        self.liner=nn.Linear(seqLen-self.wavenet.calculateReceptiveField(),output_size)\n",
    "        self.softmax=nn.Softmax(-1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.wavenet(x)\n",
    "        x=self.liner(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveNetClassifier(\n",
       "  (wavenet): WaveNet(\n",
       "    (casualConv1D): CasualDilatedConv1D(\n",
       "      (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
       "    )\n",
       "    (stackResBlock): StackOfResBlocks(\n",
       "      (resBlock_0_0): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_0_1): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(2,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_0_2): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(4,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_0_3): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(8,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_1_0): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_1_1): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(2,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_1_2): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(4,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_1_3): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(8,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_2_0): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_2_1): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(2,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_2_2): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(4,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (resBlock_2_3): ResBlock(\n",
       "        (casualDilatedConv1D): CasualDilatedConv1D(\n",
       "          (conv1D): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=same, dilation=(8,), bias=False)\n",
       "        )\n",
       "        (resConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (skipConv1D): Conv1d(1, 1, kernel_size=(1,), stride=(1,))\n",
       "        (tanh): Tanh()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (denseLayer): DenseLayer(\n",
       "      (relu): ReLU()\n",
       "      (softmax): Softmax(dim=2)\n",
       "      (conv1d): Conv1d(1, 1, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (liner): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n = WaveNetClassifier(50, 10)\n",
    "model_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
